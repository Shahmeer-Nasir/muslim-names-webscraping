# -*- coding: utf-8 -*-
"""Muslim names webscrapping

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15hKcBYkQw06wCeYvIPLCZcw3ynELwJBg

Extracting Muslim boys and girls names from hamariweb.com
"""

# Importing libraries
from bs4 import BeautifulSoup as bs
import requests

# Creating url
# Sample url 'https://hamariweb.com/names/muslim-boy-names-starting-with-a/page-2'

base_url = 'https://hamariweb.com/names/muslim-'
def get_url(gender, letter, page_num):
  return base_url + gender + '-names-starting-with-' + letter + '/page-' + str(page_num)

# Extract names from webpage

def get_names_data(soup, name_count, total_names):
  names_in_eng_urd = []
  for td in soup.find_all('td'): # Find all <td> tags
    if td.a == None:
      continue # Ignore <td> tags having no attribute
    else:
      names_in_eng_urd.append(td.a.string)
  names_in_eng = []
  for idx, name in enumerate(names_in_eng_urd):
    if(idx % 2 != 0):
      continue # Ignoring <td> tags having names in urdu
    else:
      names_in_eng.append(name)
      name_count += 1
  if name_count == total_names:
    return names_in_eng, name_count, True
  else:
    return names_in_eng, name_count, False

# Function to determine how many records (names) are there of each 
# English alphabet. This is important to be known so that our names 
# extracting loop knows how far it has to fetch data from.
# Note: It is specific to hamariweb.com html DOM structure.

def get_total_num_of_names(gender, letter):
  r = requests.get('https://hamariweb.com/names/muslim-' + gender + '-names-starting-with-' + letter + '/page-1')
  soup = bs(r.content)
  total_records_div = soup.find('div', {"class": "record_txt"})
  if total_records_div == None:
    td_tags = soup.find_all('td')
    return int(len(td_tags)/3)
  else:
    total_records_div_str = total_records_div.string
    total_records_div_list = total_records_div_str.split()
    total_records_div_list
    for idx, item in enumerate(total_records_div_list):
      if item == '(Total':
        return int(total_records_div_list[idx + 1])

# Just to test hardcodedly the number of names for an alphabet.
get_total_num_of_names('girl', 'x')

# Iterating through each page in alphabetical order
from string import ascii_lowercase as alc # For English alphabetical iteration

# Prompt for names gender
response = int(input("Enter 0 for boy or 1 for girl:"))
if response == 0:
  gender = 'boy'
elif response == 1:
  gender = 'girl'
else:
  print("Wrong input! Now extracting names for boy.")
  gender = 'boy'

all_names = [] # Final output list of names extracted, initially empty.
page_num_limit = 101 # Default limit of pages to be checked

for letter in alc:
  total_names = get_total_num_of_names(gender, letter) # Total no. of names for each alphabet
  break_loop = False
  name_count = 0

  for page_num in range(1, page_num_limit):
    print(letter, page_num) # Shows the current alphabet and page number
    full_url = get_url(gender, letter, page_num)
    print(full_url) # Shows complete URL
    r = requests.get(full_url)
    soup = bs(r.content)
    names_list, name_count, break_loop = get_names_data(soup, name_count, total_names)
    all_names.extend(names_list)
    if break_loop:
      # Loop for the current alphabet will break if iterations reach 
      # total no. of names for that alphabet.
      break
      
# Shahmeer Nasir from Bahria University

print(all_names) # Displaying extracted names

len(all_names) # Number of names extracted

# Checking if the list contains any emtpy element
for idx, name in enumerate(all_names):
  if name == '':
    print('{}. Empty'.format(idx))

# Saving names list in a text file
with open(gender + '.txt', 'w') as output:
  for name in all_names:
    output.write(str(name) + '\n')

# Shahmeer Nasir from Bahria University